#!/usr/bin/env python3
"""
æ•°æ®åº“è¿ç§»è„šæœ¬
å°†ç°æœ‰çš„å¤æ‚ç‰ˆæœ¬ç³»ç»Ÿè¿ç§»åˆ°ç®€åŒ–çš„ä¸‰ç‰ˆæœ¬ç±»å‹ç³»ç»Ÿ
"""

import sqlite3
import json
import sys
import re
from pathlib import Path
from datetime import datetime
from typing import Dict, List, Tuple, Optional

# æ·»åŠ é¡¹ç›®è·¯å¾„
sys.path.append(str(Path(__file__).parent.parent))


class VersionMigrator:
    """ç‰ˆæœ¬è¿ç§»å™¨"""
    
    def __init__(self, old_db_path: str, new_db_path: str):
        self.old_db_path = old_db_path
        self.new_db_path = new_db_path
        self.migration_log = []
    
    def analyze_existing_data(self) -> Dict:
        """åˆ†æç°æœ‰æ•°æ®"""
        print("ğŸ” åˆ†æç°æœ‰æ•°æ®...")
        
        conn = sqlite3.connect(self.old_db_path)
        cursor = conn.cursor()
        
        analysis = {
            "total_versions": 0,
            "platforms": {},
            "version_patterns": {},
            "stable_versions": [],
            "beta_versions": [],
            "alpha_versions": []
        }
        
        try:
            # æŸ¥è¯¢ç°æœ‰ç‰ˆæœ¬
            cursor.execute("""
                SELECT version, platform, architecture, is_stable, is_critical, 
                       description, release_date, total_size, file_count
                FROM versions 
                ORDER BY release_date DESC
            """)
            
            versions = cursor.fetchall()
            analysis["total_versions"] = len(versions)
            
            for version_data in versions:
                version, platform, arch, is_stable, is_critical, desc, date, size, count = version_data
                
                # ç»Ÿè®¡å¹³å°åˆ†å¸ƒ
                platform_key = f"{platform}_{arch}"
                if platform_key not in analysis["platforms"]:
                    analysis["platforms"][platform_key] = 0
                analysis["platforms"][platform_key] += 1
                
                # åˆ†æç‰ˆæœ¬æ¨¡å¼
                version_type = self._classify_version(version, is_stable, is_critical, desc)
                if version_type not in analysis["version_patterns"]:
                    analysis["version_patterns"][version_type] = 0
                analysis["version_patterns"][version_type] += 1
                
                # åˆ†ç±»ç‰ˆæœ¬
                version_info = {
                    "version": version,
                    "platform": platform,
                    "architecture": arch,
                    "description": desc,
                    "date": date,
                    "size": size,
                    "file_count": count
                }
                
                if version_type == "stable":
                    analysis["stable_versions"].append(version_info)
                elif version_type == "beta":
                    analysis["beta_versions"].append(version_info)
                else:
                    analysis["alpha_versions"].append(version_info)
            
        except Exception as e:
            print(f"âŒ åˆ†ææ•°æ®å¤±è´¥: {e}")
        finally:
            conn.close()
        
        return analysis
    
    def _classify_version(self, version: str, is_stable: bool, is_critical: bool, 
                         description: Optional[str]) -> str:
        """
        æ ¹æ®ç‰ˆæœ¬å·ã€ç¨³å®šæ€§æ ‡è®°å’Œæè¿°åˆ†ç±»ç‰ˆæœ¬
        
        åˆ†ç±»è§„åˆ™:
        - stable: is_stable=True æˆ–ç‰ˆæœ¬å·åŒ…å« "stable", "release", "final"
        - beta: ç‰ˆæœ¬å·åŒ…å« "beta", "rc", "preview" æˆ– is_stable=False ä½†ä¸æ˜¯ alpha
        - alpha: ç‰ˆæœ¬å·åŒ…å« "alpha", "dev", "test" æˆ– is_critical=True
        """
        version_lower = version.lower()
        desc_lower = (description or "").lower()
        
        # Alpha ç‰ˆæœ¬è¯†åˆ«
        alpha_keywords = ["alpha", "dev", "test", "experimental", "nightly"]
        if any(keyword in version_lower for keyword in alpha_keywords):
            return "alpha"
        if any(keyword in desc_lower for keyword in alpha_keywords):
            return "alpha"
        if is_critical:  # å…³é”®æ›´æ–°é€šå¸¸æ˜¯æµ‹è¯•æ€§è´¨çš„
            return "alpha"
        
        # Stable ç‰ˆæœ¬è¯†åˆ«
        stable_keywords = ["stable", "release", "final", "production"]
        if is_stable:
            return "stable"
        if any(keyword in version_lower for keyword in stable_keywords):
            return "stable"
        if any(keyword in desc_lower for keyword in stable_keywords):
            return "stable"
        
        # Beta ç‰ˆæœ¬è¯†åˆ«ï¼ˆé»˜è®¤ï¼‰
        beta_keywords = ["beta", "rc", "preview", "candidate"]
        if any(keyword in version_lower for keyword in beta_keywords):
            return "beta"
        if any(keyword in desc_lower for keyword in beta_keywords):
            return "beta"
        
        # æ ¹æ®ç‰ˆæœ¬å·æ¨¡å¼åˆ¤æ–­
        if re.search(r'\d+\.\d+\.\d+$', version):  # æ ‡å‡†ç‰ˆæœ¬å·æ ¼å¼
            return "stable"
        
        # é»˜è®¤ä¸º beta
        return "beta"
    
    def create_simplified_tables(self):
        """åˆ›å»ºç®€åŒ–ç‰ˆæœ¬ç®¡ç†ç³»ç»Ÿçš„æ•°æ®åº“è¡¨"""
        print("ğŸ”§ åˆ›å»ºç®€åŒ–æ•°æ®åº“è¡¨...")
        
        conn = sqlite3.connect(self.new_db_path)
        cursor = conn.cursor()
        
        try:
            # åˆ›å»ºç®€åŒ–ç‰ˆæœ¬è¡¨
            cursor.execute("""
                CREATE TABLE IF NOT EXISTS simplified_versions (
                    id INTEGER PRIMARY KEY AUTOINCREMENT,
                    version_type VARCHAR(20) NOT NULL,
                    platform VARCHAR(50) NOT NULL,
                    architecture VARCHAR(20) NOT NULL,
                    description TEXT,
                    upload_date DATETIME DEFAULT CURRENT_TIMESTAMP,
                    file_path VARCHAR(500) NOT NULL,
                    file_size BIGINT NOT NULL,
                    file_hash VARCHAR(64) NOT NULL,
                    uploader_info TEXT,
                    UNIQUE(version_type, platform, architecture)
                )
            """)
            
            # åˆ›å»ºç‰ˆæœ¬å†å²è¡¨
            cursor.execute("""
                CREATE TABLE IF NOT EXISTS version_history (
                    id INTEGER PRIMARY KEY AUTOINCREMENT,
                    version_type VARCHAR(20) NOT NULL,
                    platform VARCHAR(50) NOT NULL,
                    architecture VARCHAR(20) NOT NULL,
                    description TEXT,
                    upload_date DATETIME,
                    file_path VARCHAR(500),
                    file_size BIGINT,
                    file_hash VARCHAR(64),
                    action VARCHAR(20),
                    created_at DATETIME DEFAULT CURRENT_TIMESTAMP
                )
            """)
            
            conn.commit()
            print("âœ… æ•°æ®åº“è¡¨åˆ›å»ºæˆåŠŸ")
            
        except Exception as e:
            print(f"âŒ åˆ›å»ºæ•°æ®åº“è¡¨å¤±è´¥: {e}")
        finally:
            conn.close()
    
    def migrate_data(self, analysis: Dict) -> bool:
        """æ‰§è¡Œæ•°æ®è¿ç§»"""
        print("ğŸš€ å¼€å§‹æ•°æ®è¿ç§»...")
        
        old_conn = sqlite3.connect(self.old_db_path)
        new_conn = sqlite3.connect(self.new_db_path)
        
        try:
            old_cursor = old_conn.cursor()
            new_cursor = new_conn.cursor()
            
            # ä¸ºæ¯ä¸ªå¹³å°/æ¶æ„ç»„åˆé€‰æ‹©æœ€æ–°çš„ç‰ˆæœ¬
            platforms = ["windows", "linux", "macos"]
            architectures = ["x64", "x86", "arm64"]
            version_types = ["stable", "beta", "alpha"]
            
            migrated_count = 0
            
            for platform in platforms:
                for arch in architectures:
                    for version_type in version_types:
                        # æŸ¥æ‰¾è¯¥ç±»å‹çš„æœ€æ–°ç‰ˆæœ¬
                        latest_version = self._find_latest_version(
                            old_cursor, platform, arch, version_type
                        )
                        
                        if latest_version:
                            # è¿ç§»åˆ°æ–°ç³»ç»Ÿ
                            success = self._migrate_version(new_cursor, latest_version, version_type)
                            if success:
                                migrated_count += 1
                                self.migration_log.append(
                                    f"è¿ç§»æˆåŠŸ: {version_type}/{platform}/{arch} - {latest_version['version']}"
                                )
            
            new_conn.commit()
            print(f"âœ… æ•°æ®è¿ç§»å®Œæˆï¼Œå…±è¿ç§» {migrated_count} ä¸ªç‰ˆæœ¬")
            return True
            
        except Exception as e:
            print(f"âŒ æ•°æ®è¿ç§»å¤±è´¥: {e}")
            return False
        finally:
            old_conn.close()
            new_conn.close()
    
    def _find_latest_version(self, cursor, platform: str, arch: str, 
                           version_type: str) -> Optional[Dict]:
        """æŸ¥æ‰¾æŒ‡å®šç±»å‹çš„æœ€æ–°ç‰ˆæœ¬"""
        try:
            # æŸ¥è¯¢æ‰€æœ‰ç‰ˆæœ¬
            cursor.execute("""
                SELECT version, platform, architecture, is_stable, is_critical,
                       description, release_date, total_size, file_count
                FROM versions 
                WHERE platform = ? AND architecture = ?
                ORDER BY release_date DESC
            """, (platform, arch))
            
            versions = cursor.fetchall()
            
            # æ‰¾åˆ°åŒ¹é…ç±»å‹çš„æœ€æ–°ç‰ˆæœ¬
            for version_data in versions:
                version, plat, arc, is_stable, is_critical, desc, date, size, count = version_data
                classified_type = self._classify_version(version, is_stable, is_critical, desc)
                
                if classified_type == version_type:
                    return {
                        "version": version,
                        "platform": plat,
                        "architecture": arc,
                        "description": desc,
                        "upload_date": date,
                        "file_size": size or 0,
                        "file_count": count or 0
                    }
            
            return None
            
        except Exception as e:
            print(f"âŒ æŸ¥æ‰¾ç‰ˆæœ¬å¤±è´¥: {e}")
            return None
    
    def _migrate_version(self, cursor, version_data: Dict, version_type: str) -> bool:
        """è¿ç§»å•ä¸ªç‰ˆæœ¬åˆ°æ–°ç³»ç»Ÿ"""
        try:
            # æ„å»ºæ–‡ä»¶è·¯å¾„ï¼ˆæ¨¡æ‹Ÿï¼‰
            file_path = f"uploads/simplified/{version_data['platform']}/{version_data['architecture']}/{version_type}/{version_data['version']}.zip"
            
            # ç”Ÿæˆæ¨¡æ‹Ÿå“ˆå¸Œå€¼
            file_hash = f"migrated_{version_data['version']}_{version_type}"[:64]
            
            # å‡†å¤‡ä¸Šä¼ è€…ä¿¡æ¯
            uploader_info = json.dumps({
                "migrated_from": version_data['version'],
                "migration_date": datetime.now().isoformat(),
                "original_file_count": version_data['file_count']
            })
            
            # æ’å…¥åˆ°ç®€åŒ–ç‰ˆæœ¬è¡¨
            cursor.execute("""
                INSERT OR REPLACE INTO simplified_versions 
                (version_type, platform, architecture, description, upload_date,
                 file_path, file_size, file_hash, uploader_info)
                VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?)
            """, (
                version_type,
                version_data['platform'],
                version_data['architecture'],
                version_data['description'],
                version_data['upload_date'],
                file_path,
                version_data['file_size'],
                file_hash,
                uploader_info
            ))
            
            # è®°å½•è¿ç§»å†å²
            cursor.execute("""
                INSERT INTO version_history 
                (version_type, platform, architecture, description, upload_date,
                 file_path, file_size, file_hash, action)
                VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?)
            """, (
                version_type,
                version_data['platform'],
                version_data['architecture'],
                version_data['description'],
                version_data['upload_date'],
                file_path,
                version_data['file_size'],
                file_hash,
                'migrated'
            ))
            
            return True
            
        except Exception as e:
            print(f"âŒ è¿ç§»ç‰ˆæœ¬å¤±è´¥: {e}")
            return False
    
    def generate_migration_report(self, analysis: Dict):
        """ç”Ÿæˆè¿ç§»æŠ¥å‘Š"""
        print("\nğŸ“Š ç”Ÿæˆè¿ç§»æŠ¥å‘Š...")
        
        report = {
            "migration_date": datetime.now().isoformat(),
            "original_data": analysis,
            "migration_log": self.migration_log,
            "summary": {
                "total_original_versions": analysis["total_versions"],
                "migrated_versions": len(self.migration_log),
                "migration_success_rate": len(self.migration_log) / max(1, analysis["total_versions"]) * 100
            }
        }
        
        # ä¿å­˜æŠ¥å‘Š
        report_path = Path("migration_report.json")
        with open(report_path, 'w', encoding='utf-8') as f:
            json.dump(report, f, indent=2, ensure_ascii=False)
        
        print(f"âœ… è¿ç§»æŠ¥å‘Šå·²ä¿å­˜åˆ°: {report_path}")
        
        # æ‰“å°æ‘˜è¦
        print("\nğŸ“‹ è¿ç§»æ‘˜è¦:")
        print(f"   åŸå§‹ç‰ˆæœ¬æ•°é‡: {report['summary']['total_original_versions']}")
        print(f"   è¿ç§»ç‰ˆæœ¬æ•°é‡: {report['summary']['migrated_versions']}")
        print(f"   è¿ç§»æˆåŠŸç‡: {report['summary']['migration_success_rate']:.1f}%")


def main():
    """ä¸»å‡½æ•°"""
    print("=" * 60)
    print("ğŸ”„ Omegaç‰ˆæœ¬ç³»ç»Ÿè¿ç§»å·¥å…·")
    print("=" * 60)
    
    # æ•°æ®åº“è·¯å¾„
    old_db = "omega_updates.db"
    new_db = "omega_updates_simplified.db"
    
    if not Path(old_db).exists():
        print(f"âŒ åŸæ•°æ®åº“æ–‡ä»¶ä¸å­˜åœ¨: {old_db}")
        return
    
    # åˆ›å»ºè¿ç§»å™¨
    migrator = VersionMigrator(old_db, new_db)
    
    # åˆ†æç°æœ‰æ•°æ®
    analysis = migrator.analyze_existing_data()
    
    # åˆ›å»ºæ–°æ•°æ®åº“è¡¨
    migrator.create_simplified_tables()
    
    # æ‰§è¡Œè¿ç§»
    success = migrator.migrate_data(analysis)
    
    # ç”ŸæˆæŠ¥å‘Š
    migrator.generate_migration_report(analysis)
    
    if success:
        print("\nğŸ‰ è¿ç§»å®Œæˆï¼")
        print(f"   æ–°æ•°æ®åº“: {new_db}")
        print("   è¯·å¤‡ä»½åŸæ•°æ®åº“åï¼Œå°†æ–°æ•°æ®åº“é‡å‘½åä¸ºåŸæ•°æ®åº“åç§°")
    else:
        print("\nâŒ è¿ç§»å¤±è´¥ï¼Œè¯·æ£€æŸ¥é”™è¯¯ä¿¡æ¯")


if __name__ == "__main__":
    main()
